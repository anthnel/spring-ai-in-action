server:
  shutdown: "immediate"

spring:
  application:
    name: spring-ai-in-action

  #   main:
  #     allow-bean-definition-overriding: true

  ai:
    # ollama:
    #   init:
    #     pull-model-strategy: when-missing
    #     timeout: 2m
    #   chat:
    #     model: llama3.1:8b
    openai:
      api-key: lm-studio
    #   base-url: http://localhost:1234
    #   chat:
    #     options:
    #       stream-usage: true
    #       model: meta-llama-3.1-8b-instruct
    #       temperature: 0.5

    retry:
      max-attempts: 1

logging:
  level:
    "[org.springframework.ai]": DEBUG
    web: DEBUG
