server:
  shutdown: "immediate"

spring:
  application:
    name: spring-ai-in-action

  #   main:
  #     allow-bean-definition-overriding: true

  ai:
    ollama:
      chat:
        model: mistral:7b
    # openai:
    #   api-key: lm-studio
    #   base-url: http://localhost:1234
    #   chat:
    #     options:
    #       #   stream-usage: true
    #       model: meta-llama-3.1-8b-instruct
    #       temperature: 0.5

    retry:
      max-attempts: 1

logging:
  level:
    "[org.springframework.ai]": DEBUG
    web: DEBUG
